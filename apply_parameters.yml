## data:
image_path: "./data" # path to data folder
mask_path: "./output" # path were output will be saved (e.g, the weights of the model)
weights_path: ""
output_path: "./"
mask_ratio: 0
work_dir: None
copy: False

# model
input_shape: [1244, 1244, 3] # input shape of the model
n_classes: 3 # output classes of the model
resolutions: [0.5, 8.0] # input resolutions of the model [target, context]
hook_indexes: [0, 4] # the respective depths (starting from 0) of hooking [from, to] in the decoders
n_convs: 2 # the number of 2D convolutions per convolutional block
depth: 4 # the depth of the encoder-decoder branches
n_filters: 64 # the number of starting filters (will be increased and decreased by a factor 2 in each conv block in the encoders and decoders, respectively)
filter_size: 3 # the size of the filter in a 2D convolution
padding: "valid" # padding type in 2D convolution (either 'same' or 'valid')
batch_norm: true # boolean for using batch normalization
activation: "relu" # activation function applied after 2D convolution
learning_rate: 0.000005 # learning rate of the optimizer
l2_lambda: 0.0001 # l2 value for regulizer
opt_name: "adam" # optimizer name (either 'sgd' or 'adam')
loss_weights: [0.75, 0.25] # loss contribution for each branch [target, context]
merge_type: "concat" # method used for combining feature maps (either 'concat', 'add', 'subtract', 'multiply')
multi_loss: False
batch_size: 1

# system
queue_size: 10
cpus: 6
calc_score: True
